\section{Methodology of risk assessment}
\label{sec:Methodology of risk assessment}
Restricting the \gls{risk_assessment} to climate-related applications is not sufficient to fix every detail, e.g. how to evaluate \gls{risk} from its \glspl{determinant}. These implementation details are often expressed in the methodology chosen to perform the risk assessment.
The methodology employed in this study is presented conceptually in these paragraphs and defined operatively in sections~\ref{sec:Evaluation of indicators} and~\ref{sec:Evaluation of risk}.

The methodology is split into eight modules, each dependent on the previous ones. The following is an overview:
\begin{enumerate}
  \item \label{itm:module_1} understand the context in which the assessment is framed and identify objectives, scope and resources involved \cite[39-53]{2017GIZTheVulnerability};
  \item \label{itm:module_2} identify \glspl{risk} and \glspl{impact} affecting the system under study and determine \glspl{driver} of \gls{hazard}, \gls{exposure} and \gls{vulnerability} \cite[26-41]{2017GIZRiskSupplement};
  \item \label{itm:module_3} choose \glspl{indicator} for each \gls{driver} of \gls{hazard}, \gls{exposure} and \gls{vulnerability} \cite[73-84]{2017GIZTheVulnerability};
  \item \label{itm:module_4} collect data and quantify \glspl{indicator} \cite[87-103]{2017GIZTheVulnerability};
  \item \label{itm:module_5} normalise \glspl{indicator} to allow their comparison \cite[105-119]{2017GIZTheVulnerability};
  \item \label{itm:module_6} for each \gls{determinant}, weight normalised \glspl{indicator} and aggregate them into a single value \cite[121-131]{2017GIZTheVulnerability};
  \item \label{itm:module_7} aggregate values for individual \glspl{determinant} into a single value for \gls{risk} \cite[133-141]{2017GIZTheVulnerability};
  \item \label{itm:module_8} present the results of the \gls{CCRA} \cite[143-154]{2017GIZTheVulnerability}.
\end{enumerate}
When the \gls{vulnerability} of the system is recalled, it is split into \gls{sensitivity} and \gls{adaptive_capacity} if possible.

All modules are connected by the concept of \gls{impact_chain}, which is an \glsdesc{impact_chain}. This concept helps to develop the \gls{CCRA} as a narrative and to guide it smoothly through its various steps, see \cite[217-224]{2022KondrupClimateAdaptation} for a review of the concept.

Although a complete application of this methodology does not fall into the purposes of this study, each module is briefly addressed in the following sections and results of evaluations are presented in section~\ref{sec:Results} where case studies are treated.



\subsection{Impact chain}
\label{sec:Impact chain}
This section presents briefly scope and objectives of the \gls{CCRA} as indicated by module~\ref{itm:module_1} of the methodology. There is no direct involvement of experts and stakeholders, but literature provides for information on context and objectives for the case study. Moreover \glspl{driver} are introduced, as requested by module~\ref{itm:module_2}.

The present work is applied to impacts of climate change on airports.
The aviation sector is a complete test case for responses to climate change: it implements reduction of negative \glspl{impact} on infrastructures and transport network through adaptation measures as well as mitigation of the adverse effects on climate originated from sectorial activities \cite{2022ICAOICAOEnvironmental}. The disruption of critical infrastructures such as airports have important consequences on mobility and economic growth (see \cite{2018ICAOClimateAdaptation}, \cite[15]{2016BurbidgeAdaptingEuropean} and \cite[548]{2022DeVivoRiskAssessment} for a review of impacts). Hence, the estimation of climate \gls{risk} for airports becomes an essential tool for effective planning and risk management.

\Glspl{impact} from extreme temperatures and precipitation are studied, as they are among the biggest challenges to address in the aviation sector. Both \Gls{ICAO} and \gls{WMO} collected opinions and experiences from stakeholders through surveys \cite[62]{2018ICAOClimateAdaptation} and \cite[34]{2020WorldMeteorologicalOrganizationWMOOutcomesOf}, respectively.
More in detail, the two \gls{hazard} \glspl{driver} \gls{heat_wave} and \gls{heavy_precipitation} are considered. They are selected from the taxonomy provided by European Union for \gls{CCRA}, to have a well-known and authoritative reference in the field \cite[177]{2024EU20212139}, and both drivers are associated to acute physical risks. A symbol is associated to each \gls{driver} to track their use in the calculation, see table~\ref{tab:drivers_hazard}.
\begin{table}[h]
  \centering
  \caption{Drivers of hazard with their symbols.}
  \label{tab:drivers_hazard}
  \begin{tabular}{p{0.33\textwidth}ll}
    Driver              & Symbol        \\
    \hline
    Heat wave           & $\mathrm{HW}$ \\
    Heavy precipitation & $\mathrm{HP}$ \\
  \end{tabular}
\end{table}

An \gls{heat_wave} is defined by \gls{IPCC} as \glsdesc{heat_wave}. \Gls{WMO} presents a similar definition, highlighting the lack of a universally accepted definition, which is replaced by local criteria, although it would facilitate the exchange of information between actors \cite[5]{2023WorldMeteorologicalOrganizationWMOGuidelinesOn}. Heat waves have a wide range of impacts, particularly at the regional scale for airports, e.g. higher temperatures may damage runways or decrease the efficiency of cooling systems, changes in air density affect the runway length required for airside operations, increased humidity translates in more fog in earlier hours of the day \cite[23-28]{2018ICAOClimateAdaptation}.

For \gls{IPCC} \glsdesc{heavy_precipitation}, where the term \emph{precipitation} refers to water in every state, e.g. rain, snow, ice. Further details on the characterisation of heavy precipitation are provided by \gls{WMO} in \cite[6-7]{2023WorldMeteorologicalOrganizationWMOGuidelinesOn}. Climate change shifts local and global distributions of rainfall \cite[1605]{2021SeneviratneWeatherAnd}. These impacts are likely to occur in the near future and the one affecting airports are local in nature, e.g. flooding due to failures in drainage systems, but they may propagate throughout the aviation network depending on their severity \cite[28-34]{2018ICAOClimateAdaptation}.

\Gls{exposure} \glspl{driver} in airports are the physical components of the airport. They can be subject to \glspl{impact} of climate change at various levels, hence their presence determines \glspl{risk}. Normally the components of airports are divided in air side and land side, the former regarding all components which interact with aircraft operations and the latter for the public areas \cite[553]{2022DeVivoRiskAssessment}. This distinction is made for helping the collection of data on drivers.
In this study the considered drivers are listed in table~\ref{tab:drivers_exposure} and they are taken from \cite[554]{2022DeVivoRiskAssessment}. A single \gls{indicator} is chosen for every driver, they are listed in the same table and are identified with the same symbol, for ease.
\begin{table}[h]
  \centering
  \caption{Drivers of exposure considered in the study and associated indicators. The part of the table above the line shows the air-side components, below the line there are the land-side components. Dimensionless quantities have an empy cell in the Units column.}
  \label{tab:drivers_exposure}
  \begin{tabular}{p{0.33\textwidth}llll}
    Driver                      & Symbol        & Indicator & Units                & Torino-Caselle \\
    \hline
    Runways                     & $\mathrm{e1}$ & area      & \unit{\square\metre} & 198000         \\
    \hline
    Terminals                   & $\mathrm{e2}$ & area      & \unit{\square\metre} & 51150          \\
    Offices and other buildings & $\mathrm{e3}$ & area      & \unit{\square\metre} & 4245           \\
    Carparks                    & $\mathrm{e4}$ & number    &                      & 3000           \\
  \end{tabular}
\end{table}

\Gls{vulnerability} data are divided in \gls{adaptive_capacity} and \gls{sensitivity}. Under adaptive capacity are gathered measures which are active, planned or not present for the system in order to contain negative \glspl{impact} of climate. Instead, \glspl{driver} of sensitivity are elements of the system subject directly to the realisation of risks. Drivers are derived from \cite[555-556,558]{2022DeVivoRiskAssessment} and are listed in table~\ref{tab:drivers_vulnerability}. Similarly to the \gls{exposure} \gls{determinant}, the table shows also vulnerability \glspl{indicator}, because a single indicator is chosen for every driver and they use the same symbol.
\begin{table}[h]
  \centering
  \caption{Drivers of vulnerability and their indicators. Specifically, drivers of adaptive capacity are above the line, while drivers of sensitivity are below. Dimensionless quantities have an empty cell in the Units column.}
  \label{tab:drivers_vulnerability}
  \begin{tabular}{p{0.33\textwidth}llll}
    Driver                                           & Symbol         & Indicator & Units                & Torino-Caselle \\
    \hline
    Risk awareness                                   & $\mathrm{v1}$  & level     &                      & 0.3            \\
    Guidelines for adaptation plan to climate change & $\mathrm{v2}$  & presence  &                      & 0.5            \\
    Efficient drainage system                        & $\mathrm{v3}$  & presence  &                      & 0.1            \\
    Monitoring and alarm system                      & $\mathrm{v4}$  & presence  &                      & 0.9            \\
    Bioinfiltration and permeable pavements          & $\mathrm{v5}$  & presence  &                      & 0.1            \\
    \hline
    Soil sealing                                     & $\mathrm{v6}$  & area      & \unit{\square\metre} & 2450000        \\
    Passengers                                       & $\mathrm{v7}$  & number    &                      & 3219317        \\
    Age buildings                                    & $\mathrm{v8}$  & number    &                      & 57             \\
    Air traffic                                      & $\mathrm{v9}$  & number    &                      & 53169          \\
    Underground infrastructures                      & $\mathrm{v10}$ & area      & \unit{\square\metre} & 0              \\
    \end{tabular}
\end{table}

The \gls{CCRA} analyses a square box 3 grid cells wide centered approximately at the coordinates of the system. The systems studied in this work have spatial scale much smaller than the size of a grid cell, hence it is guaranteed that the central grid cell encompasses the systems, even if the coordinates of the centre of the system are not accurate.
Although one grid cell is enough to cover the systems under study, an extended area is chosen to increase the predictive skill of aggregation procedures applied to the spatial dimensions. On the other hand, the \gls{CCRA} would lose spatial accuracy in the description of the local events around the system, if too many grid cells are selected.
Since reference and projections datasets have same spatial resolution and coordinates (cf. sections~\ref{sec:Reference dataset} and~\ref{sec:Climate projection dataset}), same coordinates are considered for the system under study.

The reference period covered by the \gls{CCRA} of this study is chosen such that it precedes the start of the formation of the system or anticipates major changes to its structure. This arbitrary criterion is chosen to compensate the natural deteriotation of materials, with artifical buildings in mind. In fact, the methodology implicitly assumes that exposure and vulnerability values are either constant in time or their change is negligible within the period they refer to. This hypothesis and the definition of $\clim{S_\text{time}}$ together guarantee that there is no correlation in time between quantities referring to different temporal periods considered in the \gls{CCRA}.
\begin{example}
  Suppose the system under study is the Eiffel Tower. The works started in 1887 and lasted two years, hence
  \begin{equation*}
    \clim{S_\text{time}} = \{ t : \text{$t$ day from \DTMdisplaydate{1851}{1}{1}{-1} to \DTMdisplaydate{1880}{12}{31}{-1}} \}
  \end{equation*}
  is chosen as reference period. \Glspl{normal} can be evaluated for the climate data referred to $\clim{S_\text{time}}$ and data related to the system describe it as if it would not be affected by the passing of time.
  
  If the period from \DTMdisplaydate{1861}{1}{1}{-1} to \DTMdisplaydate{1890}{12}{31}{-1} were chosen instead, no assessments could be produced for the years subsequent to the end of works.
\end{example}

The future climate is described for three time horizons, they are summarised in table~\ref{tab:time_horizons}.
Near and medium-term time horizons are chosen to be as close as possible to the present (at time of writing). This way it is more reasonable to find adaptation plans and strategies for the system at risk.
Long-term time horizons are affected by greater uncertainty for different reasons, e.g. lower confidence on outputs from climate projections, exposure subject to change. Nevertheless, the long period is chosen to show differences between scenarios, which are more evident at the end of the century for many \glspl{ECV}.
\begin{table}[h]
  \centering
  \caption{Time periods used in the analysis to describe future climate and the evolution of risk.}
  \label{tab:time_horizons}
  \begin{tabular}{llll}
    Time horizon & Start                           & End                               \\
    \hline
    near         & \DTMdisplaydate{2024}{1}{1}{-1} & \DTMdisplaydate{2043}{12}{31}{-1} \\
    medium       & \DTMdisplaydate{2044}{1}{1}{-1} & \DTMdisplaydate{2063}{12}{31}{-1} \\
    long         & \DTMdisplaydate{2081}{1}{1}{-1} & \DTMdisplaydate{2100}{12}{31}{-1} \\
  \end{tabular}
\end{table}



\subsection{Evaluation of indicators}
\label{sec:Evaluation of indicators}
This section explains the process to obtain a scalar value for each \gls{determinant}, following the methodology presented in section~\ref{sec:Methodology of risk assessment}. Modules~\ref{itm:module_3}, \ref{itm:module_4}, \ref{itm:module_5} and~\ref{itm:module_6} are recalled.
Although the selection of \glspl{driver} for the actual case studies is presented in section~\ref{sec:Impact chain}, formulae involving \glspl{driver} and \glspl{indicator} are kept general.

Module~\ref{itm:module_3} may be stated symbolically as follow. For each \gls{driver} within the \gls{hazard} \gls{determinant}, a set $\mathcal{H}_j$ of \glspl{indicator} is obtained. A similar procedure is carried out for \glspl{driver} of \gls{exposure} and \gls{vulnerability}, resulting in sets $\mathcal{E}_i$ and $\mathcal{V}_k$, respectively. Indices $i$, $j$ and $k$ are present to clarify that each set is related to a different \gls{driver} and the way these sets are indexed is not important (e.g. each of them can be a sequence of integers where each one refers to a different \gls{driver}, they can be the names of the \glspl{driver} they refer to).
If the distinction between \glspl{driver} of \gls{sensitivity} and \gls{adaptive_capacity} is made, then it is not explicit in the indices. The reason is that these \glspl{driver} are treated mathematically the same way, as explained below.

Note that in module~\ref{itm:module_3} no evaluation is performed yet, hence the elements of each set are just scalar functions. In other words, they are just descriptions of how they quantify the \gls{driver}.

The methodology suggests to avoid double counting of \glspl{driver} by allocating each of them in one \gls{determinant} only \cite[29]{2017GIZRiskSupplement}. This implies to have different \glspl{indicator}, even if they are defined in a similar way.
\begin{example}
  The risk of water scarcity affecting a location is assessed. This example is inspired by \cite[46]{2017GIZRiskSupplement}. The system is the location under study.
  
  One \gls{driver} of \gls{exposure} and two of \gls{vulnerability} are chosen, they are respectively:
  \begin{description}
    \item[e1] presence of farmers in the region;
    \item[v1] insufficient know-how about irrigation systems;
    \item[v2] weak institutional setting for water management.
  \end{description}
  Both \glspl{driver} of \gls{vulnerability} describe the \gls{adaptive_capacity} of the system. All \glspl{driver} are conveniently identified by lables.
  
  An \gls{indicator} for each \gls{driver} is chosen, the resulting sets are:
  \begin{align*}
    \mathcal{E}_\text{e1} & = \left\{ \parbox{0.45\linewidth}{``number of farmers in the region''} \right\}
    \quad , \\
    \mathcal{V}_\text{v1} & = \left\{ \parbox{0.45\linewidth}{``number of farmers trained in improved irrigation techniques''} \right\}
    \quad , \\
    \mathcal{V}_\text{v2} & = \left\{ \parbox{0.45\linewidth}{``number of local water co-operations''} \right\}
    \quad .
  \end{align*}
  Note that all \glspl{indicator} consist in counting some elements of the system. Nevertheless, they are different from each other since they refer to different elements.
\end{example}

In particular for this study, an heat wave is described mathematically by \glspl{indicator} in table~\ref{tab:indicators_heat_wave}. Heat waves are described both in frequency and duration, through $\mathrm{HWI}$ and $\mathrm{HWML}$, respectively.
Indicators in table~\ref{tab:indicators_heavy_precipitation} are chosen to describe an heavy precipitation event. Other than duration and frequency, estimated by $\mathrm{CWD}$ and $\mathrm{Rp5mm}$, respectively, also the intensity of the event is quantified by $\mathrm{Rxp4day}$.
All indicators are generalised versions of indicators and indices frequently used in literature, e.g. \cite[2208]{2021GutierrezAnnexVI}. They are provided by \cite{2023BourgaultXclimXarray-based} and are evaluated at yearly resolution.
\begin{table}
  \centering
  \caption{Indicators describing heat wave events. They have yearly resolution.}
  \label{tab:indicators_heat_wave}
  \begin{tabular}{p{0.25\textwidth}lllp{0.25\textwidth}}
    Indicator            & Symbol          & Unit        & Parameters                                  & Definition                                                                                                                                        \\
    \hline
    Heat wave index      & $\mathrm{HWI}$  & \unit{\day} & $\mathrm{p1}$, $\mathrm{p2}$                & Total number of days in sequences of at least $\mathrm{p1}$ consecutive days with $\gls{tasmax} > \mathrm{p2}$                                    \\
    Heat wave max length & $\mathrm{HWML}$ & \unit{\day} & $\mathrm{p1}$, $\mathrm{p2}$, $\mathrm{p3}$ & Maximum number of days in sequences of at least $\mathrm{p1}$ consecutive days with $\gls{tasmax} > \mathrm{p2}$ and $\gls{tasmin} > \mathrm{p3}$ \\
  \end{tabular}
\end{table}
\begin{table}
  \centering
  \caption{Indicators describing heavy precipitation events. They have yearly resolution.}
  \label{tab:indicators_heavy_precipitation}
  \begin{tabular}{p{0.25\textwidth}lllp{0.25\textwidth}}
    Indicator                                           & Symbol             & Unit                & Parameters    & Definition                                                                               \\
    \hline
    Maximum consecutive $\mathrm{p4}$-day precipitation & $\mathrm{Rxp4day}$ & \unit{\milli\metre} & $\mathrm{p4}$ & Maximum cumulative precipitation in sequences of at least $\mathrm{p4}$ consecutive days \\
    Wet days                                            & $\mathrm{Rp5mm}$   & \unit{\day}         & $\mathrm{p5}$ & Total number of days with $\gls{pr} \geq \mathrm{p5}$                                    \\
    Maximum length of wet spell                         & $\mathrm{CWD}$     & \unit{\day}         & $\mathrm{p5}$ & Maximum number of consecutive days with $\gls{pr} \geq \mathrm{p5}$                      \\
  \end{tabular}
\end{table}

In module~\ref{itm:module_4} the evaluation of \glspl{indicator} on climate and system data occurs. Concerning the system, the data collection step is explained in section~\ref{sec:Impact chain} and scalar values are readily obtained for the elements in sets $\mathcal{E}_i$ and $\mathcal{V}_k$ for any \gls{driver} $i$ or $k$. See paragraphs about data in section~\ref{sec:Impact chain} for the definition of the \glspl{indicator} of \gls{exposure} and \gls{vulnerability} used to describe each system and section~\ref{sec:Results} for their values.

A more convoluted path is needed to evaluate \glspl{indicator} of \gls{hazard}. They are functions defined by equation~\eqref{eq:math_indicator}, hence they depend on climate data and additional parameters. In tables~\ref{tab:indicators_heat_wave} and~\ref{tab:indicators_heavy_precipitation} parameters are addressed to explain the definition of indicators, but in the following their choice is detailed.

For each \gls{indicator}, a set of values of its parameters is defined. Ideally these sets would be continuous, to explore the whole space of possible configurations of parameters. However, for limitations intrinsic to the analysis tools, only a finite and small number of values can be considered (in the following these discrete sets are called intervals to preserve generality).
How values in these intervals are selected depends on the nature of the parameters. The selection is ultimately arbitrary, to allow greater control, e.g. remove values which are not interesting for the analysis, and to apply a form of non-parametric sampling of the input space. This is a form of space-filling design for \gls{SA} \cite[593-594]{2015DeanHandbookOf}.

To simplify the explanation, consider \gls{driver} $j$ and an \gls{indicator} $I \in \mathcal{H}_j$. This \gls{indicator} depends on some parameters, which are collected in set $P_I$, and on some \glspl{ECV}. The chosen interval for a parameter $p \in P_I$ is a set of scalar values, possibly with units, denoted by $S_p$.

If parameter $p$ is related to a \gls{ECV} (e.g. threshold on \gls{tas}), its values are sampled from the distribution of the \gls{ECV}. First all data available for the \gls{ECV} of interest are collected in a single sample, with the following conditions:
\begin{itemize}
  \item temporal coordinates belong to the averaging period $S_\text{clim}$ chosen for the \glspl{normal};
  \item spatial coordinates are ignored.
\end{itemize}
This procedure has the side effects of removing the dependence of parameter values from spatial and temporal coordinates and to increase the sample size. The sampling is not affected by existing spatial correlation between data, because it is non parametric and regards only the possible values of the \gls{ECV} and not their spatial distribution. In fact, the probability of having any value $v$ for the \gls{ECV} $T$ in the sample is
\begin{equation}
  \label{eq:variable_probability}
  \mathcal{P}(v) = \frac{1}{\abs{S_\text{lat}} \abs{S_\text{lon}} \abs{S_\text{clim}}} \sum_{y \in S_\text{lat}} \sum_{x \in S_\text{lon}} \sum_{t \in S_\text{clim}} \condition{T(y, x, t) = v}
  \quad .
\end{equation}
It his is a frequentist probability and gets more accurate the larger the sample size is, by definition. %This probability is different from the conditional probability
%\begin{equation}
%  \label{eq:variable_probability_space}
%  \mathcal{P}(v \vert y,x) = \frac{1}{\abs{S_\text{clim}}} \sum_{t \in S_\text{clim}} \condition{T(y, x, t) = v}
%\end{equation}
%where the dependence on the spatial coordinates is retained.
Second, the empirical \gls{QF} of data is built from the sample, to acknowledge the shape of their true probability distribution. Minimum and maximum values are treated as the first and last quantiles, respectively. Since the number of data is large but limited, this curve is an approximation of the inverse function of the \gls{CDF} and missing data are interpolated linearly.
Third, values are chosen with the aim to sample the true probability distribution uniformly, starting from the quantile corresponding to frequency 90\%. This allows to focus the analysis on the side of the distribution which have higher values, related to extreme \glspl{risk}. The density of points may be increased where needed to have a better description of the shape of the distribution.%
\footnote{Why do not use derivative-based methods to set the density of points? The reason is again greater control on the selected values: there is no need to evaluate the derivative of the \gls{QF} in every point, just within the subintervals which are interesting for the analysis. Note that the \gls{QF} is obtained by linear interpolation between existent data values, hence the slope is already evaluated internally and the derivative is a piecewise constant function.}

If parameter $p$ is not related to a \gls{ECV} (e.g. window size for moving averages), some heuristic is applied and explained case by case where values are presented in section~\ref{sec:Results}.

The parameters indicators chosen for this study depend on are collected in table~\ref{tab:indicators_parameters}. Note that despite the definition of heat wave lasting two or more day, a window of one day is considered, i.e. $\mathrm{p1} = 1$, simply to count the number of days with extreme temperatures in a year. In particular, indicator $\mathrm{HWI}$ becomes $\mathrm{TXnn}$, see \cite[2209]{2021GutierrezAnnexVI}.
\begin{table}[h]
  \centering
  \caption{Parameters present in the definitions of hazard indicators.}
  \label{tab:indicators_parameters}
  \begin{tabular}{p{0.33\textwidth}llp{0.33\textwidth}}
    Parameter                                  & Symbol        & Unit                        & Interval                                                                               \\
    \hline
    Consecutive days of extreme heat           & $\mathrm{p1}$ & \unit{\day}                 & Integer numbers from 1 to 31 in steps of 3                                             \\  %Interval in symbols: $\{ v \in \mathbb{N} : v = 3n + 1 \wedge n \in \mathbb{N} \wedge 0 \leq n \leq 10 \}$.
    Threshold of \gls{tasmax}                  & $\mathrm{p2}$ & \unit{\degreeCelsius}       & Quantiles 0.90, 0.97, 0.99, 0.999, 0.9999 of \gls{tasmax} in the historical experiment \\
    Threshold of \gls{tasmin}                  & $\mathrm{p3}$ & \unit{\degreeCelsius}       & Quantiles 0.90, 0.97, 0.99, 0.999, 0.9999 of \gls{tasmin} in the historical experiment \\
    Consecutive days of extreme precipitation  & $\mathrm{p4}$ & \unit{\day}                 & Integer numbers from 1 to 31                                                           \\  %Interval in symbols: $\{ v \in \mathbb{N} : 1 \leq v \leq 31 \}$.
    Threshold of \gls{pr}                      & $\mathrm{p5}$ & \unit{\milli\metre\per\day} & Quantiles 0.90, 0.97, 0.99, 0.999, 0.9999 of \gls{pr} in the historical experiment     \\
  \end{tabular}
\end{table}

After $S_p$ is defined for every $p \in P_I$, the \gls{indicator} $I$ is finally evaluated. This results in elements of set $\mathcal{H}_j$ being multidimensional arrays given by equation~\eqref{eq:math_indicator}, for every \gls{driver} $j$ of the \gls{hazard}. Different \glspl{indicator} may have different parameters, but they depend on \glspl{ECV} which same spatial and temporal coordinates $S_\text{lat} \times S_\text{lon} \times S_\text{clim}$, hence they have same temporal frequency, i.e. same $S_\text{y}$.

From a computational perspective, the time complexity for the evaluation of an \gls{hazard} \gls{indicator} $I$ is a particular function $f$ of the number $\abs{S_\text{time}}$ of temporal coordinates of climate data.%
\footnote{Here time complexity is intended as number of steps of an algorithm, which can be related to physical time when executed on a calculator.}
The evaluation is then repeated for every spatial coordinate in $S_\text{lat} \times S_\text{lon}$, year in $S_\text{y}$ and combination of parameters $\underline{z} \in \prod_{p \in P_I} S_p$. In symbols the time complexity is
\begin{equation}
  \label{eq:complexity_parameters}
  O \bigg( f \big( \abs{S_\text{time}} \big) \abs{S_\text{lat}} \abs{S_\text{lon}} \abs{S_\text{y}} \prod_{p \in P_I} \abs{S_p} \bigg)
  \quad .
\end{equation}
For indicators in table~\ref{tab:indicators_parameters}, the evaluation time of an indicator for a single choice of its arguments can be always bounded by polynomial functions, $f \big( \abs{S_\text{time}} \big) = \big( \abs{S_\text{time}} \big)^a $, with $a \in \mathbb{R}$ specific to the indicator being evaluated. This means that the computation benefit from a parallel setup.

\Glspl{indicator} are also evaluated for each model available (see table~\ref{tab:CMIP6_models}). A different model may have different values for an \gls{ECV} at the same coordinates. Moreover, these differences reflect on the procedures of evaluation of parameters values. Therefore, parameters defined as quantiles of \glspl{ECV} are expressed by their probability rather than their value.

These results need further elaboration. In fact, for every \gls{driver} $i$ and $k$, $\mathcal{E}_i$ and $\mathcal{V}_k$ contain scalar values which encapsulate information about the system for the chosen time period and system without reference to spatial coordinates. To obtain an analogous result for \glspl{driver} of \gls{hazard}, \glspl{indicator} are aggregated over spatial and temporal dimensions. For simplicity intermediate results are identified with the same variable $I$.
First, the temporal aggregation is performed. It consists in averaging the multidimensional array over the temporal dimension with a sample average. The outcome is multidimensional arrays depending on spatial coordinates and parameters:
\begin{equation}
  \label{eq:temporal_aggregation}
  I(y, x, t, \underline{z}) \mapsto I(y, x, \underline{z}) = \frac{1}{\abs{S_\text{y}}} \sum_{t \in S_\text{y}} I(y, x, t, \underline{z})
  \quad .
\end{equation}
Due to the spatial resolution of data, they may contain bias with respect to the reference period, e.g. orography may influence differently the variation of some \glspl{ECV}. Therefore, for every \glspl{indicator} $I$, its relative variation with respect to the reference period is used,
\begin{equation}
  \label{eq:spatial_bias}
  I(y, x, \underline{z}) \mapsto I(y, x, \underline{z}) = I(y, x, \underline{z}) - I_\text{clim}(y, x, \underline{z})
  \quad ,
\end{equation}
where symbol $I_\text{clim}$ is used to refer to $I$ evaluated for the reference period, i.e. equation~\eqref{eq:temporal_aggregation} with $S_\text{y} = S_\text{clim}$. This is analogous to evaluate \glspl{anomaly} for \glspl{indicator} instead of \glspl{ECV}.
Then, the spatial aggregation is performed by using \gls{EOF} analysis as a dimensionality reduction technique.%
\footnote{Terminology is varied. Here the eigenvectors, i.e. spatial patterns, are referred to as \glspl{EOF} and their coefficients, i.e. temporal patterns, are the \glspl{PC}. The object containig data is called design matrix with samples, i.e. observations, organised in rows and their features, i.e. variables which describe them, in columns. For further clarification on the terminology see \cite[626-627]{2019WilksStatisticalMethods} and for a recap on \gls{EOF} analysis see \cite[6502-6503]{2009MonahanEmpiricalOrthogonal} and \cite[1121-1122]{2007HannachiEmpiricalOrthogonal}.}
The following procedure is applied to every \gls{indicator} $I$ in its multidimensional array representation:
\begin{enumerate}
  \item assign $S_\text{lat} \times S_\text{lon}$ as the feature dimension of the design matrix;
  \item \label{itm:sample_dimension} assign $\prod_{p \in P_I} S_p$ as the sample dimension of the design matrix;
  \item apply the \gls{EOF} analysis to the design matrix;
  \item keep the first \gls{PC} only, i.e. the coefficients corresponding to the \gls{EOF} which maximises the variance in the sample dimension.
\end{enumerate}
In point~\ref{itm:sample_dimension} of the procedure, a bijective relations between the sample dimension of the design matrix and $\prod_{p \in P_I} S_p$ is established, hence the first \gls{PC} effectively maps $I$ to a multidimensional array with coordinates in $\prod_{p \in P_I} S_p$:
\begin{equation}
  \label{eq:spatial_aggregation}
  I(y, x, \underline{z}) \mapsto I(\underline{z})% = \EOF{I(y, x, \underline{z})}  % If the commented notation is used, then add to main.tex: \DeclarePairedDelimiterXPP{\EOF}[1]{\mathrm{EOF}}{[}{]}{}{#1}.
  \quad .
\end{equation}
After the spatial and temporal aggregations, for every \gls{driver} $j$ each element $I \in \mathcal{H}_j$ depends only on parameter values in $\prod_{p \in P_I} S_p$.

To execute module~\ref{itm:module_5}, first the scale of each \gls{indicator} is defined. In this work all \glspl{indicator} are numeric values and may have both metric or categorical scales (i.e. values are distributed uniformly or not, respectively, cf. \cite[109]{2017GIZTheVulnerability}).
When metric scales are involved, the methodology suggests to apply the min-max normalisation. Instead, in the present work \glspl{indicator} which are scalar values are not transformed,%
\footnote{Formally they are divided by a unit value of their quantity to obtain dimensionless values, which are trivially compatible and easily used as arguments in mathematical functions. Note that this is not necessary for \gls{hazard} \glspl{indicator} because of the procedure to remove bias from climatology.}
while \glspl{indicator} which depend on parameters are standardised, i.e. substituted by their z-score. More in detail, for any \gls{indicator} $I$ undergoing normalisation, the new value is
\begin{equation}
  \label{eq:z-score}
  I(\underline{z}) \mapsto I(\underline{z}) = \frac{I(\underline{z}) - \mu_I}{\sigma_I}
\end{equation}
where the sample mean
\begin{equation}
  \label{eq:sample_mean}
  \mu_I = \frac{1}{\prod_{p \in P_I} \abs{S_p}} \sum_{\underline{z} \in \prod_{p \in P_I} S_p} I_\text{clim}(\underline{z})
\end{equation}
and the sample standard deviation
\begin{equation}
  \label{eq:sample_standard_deviation}
  \sigma_I = \sqrt{\frac{1}{\prod_{p \in P_I} \abs{S_p} - 1} \sum_{\underline{z} \in \prod_{p \in P_I} S_p} \big( I_\text{clim}(\underline{z}) - \mu_I \big)^2}
\end{equation}
are calculated using values obtained for the reference period $S_\text{clim}$ \cite[84]{2008OECDHandbookOn}. The advantage of equation~\eqref{eq:z-score} with respect to min-max normalisation is to be flexible when new values are introduced, in fact they are measured in terms of statistics of the reference period without breaking the normalisation.%
\footnote{See section~\ref{sec:Min-max normalisation} for further insight on why min-max normalisation is not used.}
To normalise categorical scales, the methodology suggests first to group the values in five classes, then replace them with specific values in the range $[0, 1]$, see \cite[115-116]{2017GIZTheVulnerability}. Higher normalised values are associated to more negative impacts. However, this case does not occur in the present study since every \gls{indicator} with categorical scale is a constant value. Not normalising some \glspl{indicator} may seem wrong since normalisation is a requisite to compare them, but the reason is supported mathematically in the next paragraphs.

For module~\ref{itm:module_6}, the weight $w_I$ of each \gls{indicator} $I$ is set to 1, because no particular influence on the final \gls{risk} is known a priori. Since \glspl{indicator} are unique, there is not ambiguity to identify their weights with their names as labels. This choice of weighting has not effects on the final \gls{risk} value, as explained in section~\ref{sec:Evaluation of risk}.
Then, for each \gls{determinant} the weighted mean of its \glspl{indicator} is computed. Since all \glspl{indicator} are weighted equally, the result equals the arithmetic mean. In \cite[51]{2017GIZRiskSupplement} this process is represented graphically with a single \gls{indicator} for each \gls{driver}.
The results are a scalar value for \gls{exposure}
\begin{equation}
  \label{eq:exposure_aggregated}
  E = \frac{1}{\sum_i \sum_{I \in \mathcal{E}_i} w_I} \sum_i \sum_{I \in \mathcal{E}_i} w_I I
  \quad ,
\end{equation}
a scalar value for \gls{vulnerability}
\begin{equation}
  \label{eq:vulnerability_aggregated}
  V = \frac{1}{\sum_k \sum_{I \in \mathcal{V}_k} w_I} \sum_k \sum_{I \in \mathcal{V}_k} w_I I
\end{equation}
and a scalar function for \gls{hazard} $H : \prod_j \prod_{I \in \mathcal{H}_j} \prod_{p \in P_I} S_p \to \mathbb{R}$, which depends on all parameters, defined as
\begin{equation}
  \label{eq:hazard_aggregated}
  H(\underline{z}) = \frac{1}{\sum_j \sum_{I \in \mathcal{H}_j} w_I} \sum_j \sum_{I \in \mathcal{H}_j} w_I I(\underline{z}_I)
\end{equation}
where $\underline{z}_I \in \prod_{p \in P_I} S_p$ is the sequence of values for parameters which are arguments of $I$.
Note that the there is no need to treat \glspl{driver} of \gls{adaptive_capacity} and \gls{sensitivity} separately because the aggregation procedure is applied equally to them.

Note that in module~\ref{itm:module_6} a relation between \glspl{indicator} within the same \gls{determinant} is established through the aggregation procedure, hence the results may be regarded as category~\ref{itm:category_1} complex \glspl{hazard}.
Moreover, the concept of intermediate impact, which mediates \glspl{driver} of hazard and \gls{vulnerability}, are a form of category~\ref{itm:category_2} complex \gls{hazard} \cite[33]{2017GIZRiskSupplement}.



\subsection{Evaluation of risk}
\label{sec:Evaluation of risk}
Scalar values representing each \gls{determinant} of \gls{risk} are aggregated into a single value. The aggregation procedure is a weighted mean, see module~\ref{itm:module_7}, and the weights assigned to each \gls{determinant} are $w_E = 1$, $w_H = 1$ and $w_V = 1$. Then, analogously to the aggregation of \gls{hazard} \glspl{indicator} in equation~\ref{eq:hazard_aggregated}, the value for \gls{risk} is a scalar function $R : \prod_j \prod_{I \in \mathcal{H}_j} \prod_{p \in P_I} S_p \to \mathbb{R}$ which depends on all parameters:
\begin{equation}
  \label{eq:risk_aggregated}
  R(\underline{z}) = \frac{w_E E + w_H H(\underline{z}) + w_V V}{w_E + w_H + w_V}
  \quad .
\end{equation}
The \gls{risk} value is a linear function of normalised \gls{hazard} \glspl{indicator}. This can be seen easily by manipulating equation~\eqref{eq:risk_aggregated},
\begin{equation}
  \label{eq:risk_linearity}
  R(\underline{z}) = c_0 + \frac{w_H H(\underline{z})}{w_E + w_H + w_V} = c_0 + c_1 \sum_j \sum_{I \in \mathcal{H}_j} w_I I(\underline{z}_I)
\end{equation}
with $c_0 = \frac{w_E E + w_V V}{w_E + w_H + w_V}$ and $c_1 = \frac{w_H}{(w_E + w_H + w_V) \sum_j \sum_{I \in \mathcal{H}_j} w_I}$, and it holds true as long as the aggregation procedures for \gls{risk} and \gls{hazard} are linear.

One of the problems which justifies this work can be stated using equation~\eqref{eq:risk_aggregated}: given different choices of \glspl{indicator} or parameters, the resulting \gls{risk} value can be the same, as long as the differences in values balance out.
\begin{example}
  \Gls{risk} is assessed for a system, $E$ and $V$ are known and only one \gls{driver} of \gls{hazard} is considered. Two sets of different \glspl{indicator} are prepared, $\mathcal{H}'$ and $\mathcal{H}''$, functions may differ only in the values of their parameters.These alternatives would be equivalent to describe the \gls{driver} mathematically from different points of view.
  
  Even if all \glspl{indicator} have different values after the calculation steps, the aggregated values of \gls{hazard} $H'$ and $H''$ for sets $\mathcal{H}'$ and $\mathcal{H}''$, respectively, are ideally equal. The same same \gls{risk} value $R$ results from the aggregation, since $E$ and $V$ do not depend on the choices regarding the \gls{hazard}.
  This is the expected outcome, because changing the mathematical description of the physical phenomenon should not change the final \gls{risk}.
\end{example}

A final non-linear transformation is performed on \gls{risk} value $R$, to simplify the presentation and comparison of \gls{risk} values.
Values obtained from all the combinations of parameters are classified accordingly to five categories, in increasing order of severity:\cite[53]{2017GIZRiskSupplement}
\begin{enumerate}
  \item $\riski$;
  \item $\riskii$;
  \item $\riskiii$;
  \item $\riskiv$;
  \item $\riskv$.
\end{enumerate}
This transformation can be formalised as a piecewise function $r : \prod_j \prod_{I \in \mathcal{H}_j} \prod_{p \in P_I} S_p \to \{ \riski, \riskii, \riskiii, \riskiv, \riskv \}$, where the thresholds for each piece are the quantiles of the image of $\prod_j \prod_{I \in \mathcal{H}_j} \prod_{p \in P_I} S_p$ through function $R$ for the reference period:
\begin{equation}
  \label{eq:risk_categorical}
  r(\underline{z}) =
  \begin{cases}
    \riski & R(\underline{z}) < q_1 \\
    \riskii & q_1 \le R(\underline{z}) < q_2 \\
    \riskiii & q_2 \le R(\underline{z}) < q_3 \\
    \riskiv & q_3 \le R(\underline{z}) < q_4 \\
    \riskv & R(\underline{z}) \ge q_4
  \end{cases}
  \quad .
\end{equation}
Thresholds $q_1$, $q_2$, $q_3$ and $q_4$ are calculated from \gls{risk} values of the reference period because \gls{hazard} \glspl{driver} are supposed to change \gls{risk} and \glspl{impact} with time. Moreover, the pieces of the function reflect the fact that the image of $R$ is not bounded, due to the aggregated values of \glspl{determinant} being not bounded by the chosen normalisation. This allows to account for extreme values of \gls{risk} in periods different from the reference.

Module~\ref{itm:module_7} addresses the possible aggregation of multiple sub-risks into an overall \gls{risk} value \cite[54]{2017GIZRiskSupplement}. According to section~\ref{sec:Complex risk}, the outcome would be a complex risk belonging to category~\ref{itm:category_3}.
This additional elaboration is not implemented in the present work because an individual \gls{risk} is studied, i.e. the climate risk.
