\section{Methodology of risk assessment}
\label{sec:Methodology of risk assessment}
Restricting the \gls{risk_assessment} to climate-related applications is not sufficient to fix every detail, e.g. how to evaluate \gls{risk} from its \glspl{determinant}. These implementation details are often expressed in the methodology chosen to perform the risk assessment.
The methodology employed in this study is presented conceptually in these paragraphs and defined operatively in sections~\ref{sec:Evaluation of indicators} and~\ref{sec:Evaluation of risk}.

The methodology is split into eight modules, each dependent on the previous ones. The following is an overview:
\begin{enumerate}
  \item \label{itm:module_1} understand the context in which the assessment is framed and identify objectives, scope and resources involved \cite[39-53]{2017GIZTheVulnerability};
  \item \label{itm:module_2} identify \glspl{risk} and \glspl{impact} affecting the system under study and determine \glspl{driver} of \gls{hazard}, \gls{exposure} and \gls{vulnerability} \cite[26-41]{2017GIZRiskSupplement};
  \item \label{itm:module_3} choose \glspl{indicator} for each \gls{driver} of \gls{hazard}, \gls{exposure} and \gls{vulnerability} \cite[73-84]{2017GIZTheVulnerability};
  \item \label{itm:module_4} collect data and quantify \glspl{indicator} \cite[87-103]{2017GIZTheVulnerability};
  \item \label{itm:module_5} normalise \glspl{indicator} to allow their comparison \cite[105-119]{2017GIZTheVulnerability};
  \item \label{itm:module_6} for each \gls{determinant}, weight normalised \glspl{indicator} and aggregate them into a single value \cite[121-131]{2017GIZTheVulnerability};
  \item \label{itm:module_7} aggregate values for individual \glspl{determinant} into a single value for \gls{risk} \cite[133-141]{2017GIZTheVulnerability};
  \item \label{itm:module_8} present the results of the \gls{CCRA} \cite[143-154]{2017GIZTheVulnerability}.
\end{enumerate}
When the \gls{vulnerability} of the system is recalled, it is split into \gls{sensitivity} and \gls{adaptive_capacity} if possible.

All modules are connected by the concept of \gls{impact_chain}, which is an \glsdesc{impact_chain}. This concept helps to develop the \gls{CCRA} as a narrative and to guide it smoothly through its various steps, see \cite[217-224]{2022KondrupClimateAdaptation} for a review of the concept.

Although a complete application of this methodology does not fall into the purposes of this study, each module is briefly addressed in the following sections and results of evaluations are presented in section~\ref{sec:Results} where case studies are treated.



\subsection{Impact chain}
\label{sec:Impact chain}
This section presents briefly scope and objectives of the \gls{CCRA} as indicated by module~\ref{itm:module_1} of the methodology. There is no direct involvement of experts and stakeholders, but literature provides for information on context and objectives for the case study. Moreover \glspl{driver} are introduced, as requested by module~\ref{itm:module_2}.

The present work is applied to impacts of climate change on airports.
The aviation sector is a complete test case for responses to climate change: it implements reduction of negative \glspl{impact} on infrastructures and transport network through adaptation measures as well as mitigation of the adverse effects on climate originated from sectorial activities \cite{2022ICAOICAOEnvironmental}. The disruption of critical infrastructures such as airports have important consequences on mobility and economic growth (see \cite{2018ICAOClimateAdaptation}, \cite[15]{2016BurbidgeAdaptingEuropean} and \cite[548]{2022DeVivoRiskAssessment} for a review of impacts). Hence, the estimation of climate \gls{risk} for airports becomes an essential tool for effective planning and risk management.

\Glspl{impact} from extreme temperatures and precipitation are studied, as they are among the biggest challenges to address in the aviation sector. Both \Gls{ICAO} and \gls{WMO} collected opinions and experiences from stakeholders through surveys \cite[62]{2018ICAOClimateAdaptation} and \cite[34]{2020WorldMeteorologicalOrganizationWMOOutcomesOf}, respectively.
More in detail, the two \gls{hazard} \glspl{driver} \gls{heat_wave} and \gls{heavy_precipitation} are considered. They are selected from the taxonomy provided by European Union for \gls{CCRA}, to have a well-known and authoritative reference in the field \cite[177]{2024EU20212139}, and both drivers are associated to acute physical risks. A symbol is associated to each \gls{driver} to track their use in the calculation, see table~\ref{tab:drivers_hazard}.
\begin{table}[h]
  \centering
  \caption{Drivers of hazard with their symbols.}
  \label{tab:drivers_hazard}
  \begin{tabular}{lc}
    Driver              & Symbol        \\
    \hline
    Heat wave           & $\mathrm{HW}$ \\
    Heavy precipitation & $\mathrm{HP}$ \\
  \end{tabular}
\end{table}

An \gls{heat_wave} is defined by \gls{IPCC} as \glsdesc{heat_wave}. \Gls{WMO} presents a similar definition, highlighting the lack of a universally accepted definition, which is replaced by local criteria, although it would facilitate the exchange of information between actors \cite[5]{2023WorldMeteorologicalOrganizationWMOGuidelinesOn}. Heat waves have a wide range of impacts, particularly at the regional scale for airports, e.g. higher temperatures may damage runways or decrease the efficiency of cooling systems, changes in air density affect the runway length required for airside operations, increased humidity translates in more fog in earlier hours of the day \cite[23-28]{2018ICAOClimateAdaptation}.

For \gls{IPCC} \glsdesc{heavy_precipitation}, where the term \emph{precipitation} refers to water in every state, e.g. rain, snow, ice. Further details on the characterisation of heavy precipitation are provided by \gls{WMO} in \cite[6-7]{2023WorldMeteorologicalOrganizationWMOGuidelinesOn}. Climate change shifts local and global distributions of rainfall \cite[1605]{2021SeneviratneWeatherAnd}. These impacts are likely to occur in the near future and the one affecting airports are local in nature, e.g. flooding due to failures in drainage systems, but they may propagate throughout the aviation network depending on their severity \cite[28-34]{2018ICAOClimateAdaptation}.

\Gls{exposure} \glspl{driver} in airports are the physical components of the airport. They can be subject to \glspl{impact} of climate change at various levels, hence their presence determines \glspl{risk}. Normally the components of airports are divided in air side and land side, the former regarding all components which interact with aircraft operations and the latter for the public areas \cite[553]{2022DeVivoRiskAssessment}. This distinction is made for helping the collection of data on drivers.
In this study the considered drivers are listed in table~\ref{tab:drivers_exposure} and they are taken from \cite[554]{2022DeVivoRiskAssessment}. A single \gls{indicator} is chosen for every driver, they are listed in the same table and are identified with the same symbol, for ease.
\begin{table}[h]
  \centering
  \caption{Drivers of exposure considered in the study and associated indicators. The part of the table above the line shows the air-side components, below the line there are the land-side components. Dimensionless quantities have an empy cell in the Units column.}
  \label{tab:drivers_exposure}
  \begin{tabular}{p{0.20\textwidth}cccc}
    Driver                      & Symbol        & Indicator & Units                & Torino-Caselle \\
    \hline
    Runways                     & $\mathrm{e1}$ & area      & \unit{\square\metre} & 198000         \\
    \hline
    Terminals                   & $\mathrm{e2}$ & area      & \unit{\square\metre} & 51150          \\
    Offices and other buildings & $\mathrm{e3}$ & area      & \unit{\square\metre} & 4245           \\
    Carparks                    & $\mathrm{e4}$ & number    &                      & 3000           \\
  \end{tabular}
\end{table}

\Gls{vulnerability} data are divided in \gls{adaptive_capacity} and \gls{sensitivity}. Under adaptive capacity are gathered measures which are active, planned or not present for the system in order to contain negative \glspl{impact} of climate. Instead, \glspl{driver} of sensitivity are elements of the system subject directly to the realisation of risks. Drivers are derived from \cite[555-556,558]{2022DeVivoRiskAssessment} and are listed in table~\ref{tab:drivers_vulnerability}. Similarly to the \gls{exposure} \gls{determinant}, the table shows also vulnerability \glspl{indicator}, because a single indicator is chosen for every driver and they use the same symbol.
\begin{table}[h]
  \centering
  \caption{Drivers of vulnerability and their indicators. Specifically, drivers of adaptive capacity are above the line, while drivers of sensitivity are below. Dimensionless quantities have an empty cell in the Units column.}
  \label{tab:drivers_vulnerability}
  \begin{tabular}{p{0.20\textwidth}cccc}
    Driver                                           & Symbol         & Indicator & Units                & Torino-Caselle \\
    \hline
    Risk awareness                                   & $\mathrm{v1}$  & level     &                      & 0.3            \\
    Guidelines for adaptation plan to climate change & $\mathrm{v2}$  & presence  &                      & 0.5            \\
    Efficient drainage system                        & $\mathrm{v3}$  & presence  &                      & 0.1            \\
    Monitoring and alarm system                      & $\mathrm{v4}$  & presence  &                      & 0.9            \\
    Bioinfiltration and permeable pavements          & $\mathrm{v5}$  & presence  &                      & 0.1            \\
    \hline
    Soil sealing                                     & $\mathrm{v6}$  & area      & \unit{\square\metre} & 2450000        \\
    Passengers                                       & $\mathrm{v7}$  & number    &                      & 3219317        \\
    Age buildings                                    & $\mathrm{v8}$  & number    &                      & 57             \\
    Air traffic                                      & $\mathrm{v9}$  & number    &                      & 53169          \\
    Underground infrastructures                      & $\mathrm{v10}$ & area      & \unit{\square\metre} & 0              \\
    \end{tabular}
\end{table}

The \gls{CCRA} analyses a square box 3 grid cells wide centered approximately at the coordinates of the system. The systems studied in this work have spatial scale much smaller than the size of a grid cell, hence it is guaranteed that the central grid cell encompasses the systems, even if the coordinates of the centre of the system are not accurate.
Although one grid cell is enough to cover the systems under study, an extended area is chosen to increase the predictive skill of aggregation procedures applied to the spatial dimensions. On the other hand, the \gls{CCRA} would lose spatial accuracy in the description of the local events around the system, if too many grid cells are selected.
Since reference and projections datasets have same spatial resolution and coordinates (cf. sections~\ref{sec:Reference dataset} and~\ref{sec:Climate projection dataset}), same coordinates are considered for the system under study.

The reference period covered by the \gls{CCRA} of this study is chosen such that it precedes the start of the formation of the system or anticipates major changes to its structure. This arbitrary criterion is chosen to compensate the natural deteriotation of materials, with artifical buildings in mind. In fact, the methodology implicitly assumes that exposure and vulnerability values are either constant in time or their change is negligible within the period they refer to. This hypothesis and the definition of the reference period together guarantee that there is no correlation in time between quantities referring to different temporal periods considered in the \gls{CCRA}.
\begin{example}
  Suppose the system under study is the Eiffel Tower. The works started in 1887 and lasted two years, hence
  \begin{equation*}
    \prd{S_\text{time}}{ref} = \{ t : \text{$t$ day from \DTMdisplaydate{1851}{1}{1}{-1} to \DTMdisplaydate{1880}{12}{31}{-1}} \}
  \end{equation*}
  is chosen as reference period. \Glspl{normal} can be evaluated for the climate data referred to $\prd{S_\text{time}}{ref}$ and data related to the system describe it as if it would not be affected by the passing of time.
  
  If the period from \DTMdisplaydate{1861}{1}{1}{-1} to \DTMdisplaydate{1890}{12}{31}{-1} were chosen instead, no assessments could be produced for the years subsequent to the end of works.
\end{example}

The future climate is described for three time horizons, they are summarised in table~\ref{tab:time_horizons}.
Near and medium-term time horizons are chosen to be as close as possible to the present (at time of writing). This way it is more reasonable to find adaptation plans and strategies for the system at risk.
Long-term time horizons are affected by greater uncertainty for different reasons, e.g. lower confidence on outputs from climate projections, exposure subject to change. Nevertheless, the long period is chosen to show differences between scenarios, which are more evident at the end of the century for many \glspl{ECV}.
\begin{table}[h]
  \centering
  \caption{Time periods used in the analysis to describe future climate and the evolution of risk.}
  \label{tab:time_horizons}
  \begin{tabular}{lccc}
    Time horizon & Symbol & Start                           & End                               \\
    \hline
    Near         & near   & \DTMdisplaydate{2024}{1}{1}{-1} & \DTMdisplaydate{2043}{12}{31}{-1} \\
    Medium       & mid    & \DTMdisplaydate{2044}{1}{1}{-1} & \DTMdisplaydate{2063}{12}{31}{-1} \\
    Long         & long   & \DTMdisplaydate{2081}{1}{1}{-1} & \DTMdisplaydate{2100}{12}{31}{-1} \\
  \end{tabular}
\end{table}



\subsection{Evaluation of indicators}
\label{sec:Evaluation of indicators}
This section explains the process to obtain a scalar value for each \gls{determinant}, following the methodology presented in section~\ref{sec:Methodology of risk assessment}. Modules~\ref{itm:module_3}, \ref{itm:module_4}, \ref{itm:module_5} and~\ref{itm:module_6} are recalled.
Although the selection of \glspl{driver} for the actual case studies is presented in section~\ref{sec:Impact chain}, formulae involving \glspl{driver} and \glspl{indicator} are kept general.

Module~\ref{itm:module_3} may be stated symbolically as follow. For each \gls{driver} within the \gls{hazard} \gls{determinant}, a set $\mathcal{H}_j$ of \glspl{indicator} is obtained. A similar procedure is carried out for \glspl{driver} of \gls{exposure} and \gls{vulnerability}, resulting in sets $\mathcal{E}_i$ and $\mathcal{V}_k$, respectively. Indices $i$, $j$ and $k$ are present to clarify that each set is related to a different \gls{driver} and the way these sets are indexed is not important (e.g. each of them can be a sequence of integers where each one refers to a different \gls{driver}, they can be the names of the \glspl{driver} they refer to).
If the distinction between \glspl{driver} of \gls{sensitivity} and \gls{adaptive_capacity} is made, then it is not explicit in the indices. The reason is that these \glspl{driver} are treated mathematically the same way, as explained below.

Note that in module~\ref{itm:module_3} no evaluation is performed yet, hence the elements of each set are just scalar functions. In other words, they are just descriptions of how they quantify the \gls{driver}.

The methodology suggests to avoid double counting of \glspl{driver} by allocating each of them in one \gls{determinant} only \cite[29]{2017GIZRiskSupplement}. This implies to have different \glspl{indicator}, even if they are defined in a similar way.
\begin{example}
  The risk of water scarcity affecting a location is assessed. This example is inspired by \cite[46]{2017GIZRiskSupplement}. The system is the location under study.
  
  One \gls{driver} of \gls{exposure} and two of \gls{vulnerability} are chosen, they are respectively:
  \begin{description}
    \item[e1] presence of farmers in the region;
    \item[v1] insufficient know-how about irrigation systems;
    \item[v2] weak institutional setting for water management.
  \end{description}
  Both \glspl{driver} of \gls{vulnerability} describe the \gls{adaptive_capacity} of the system. All \glspl{driver} are conveniently identified by lables.
  
  An \gls{indicator} for each \gls{driver} is chosen, the resulting sets are:
  \begin{align*}
    \mathcal{E}_\text{e1} & = \left\{ \parbox{0.45\linewidth}{``number of farmers in the region''} \right\}
    \quad , \\
    \mathcal{V}_\text{v1} & = \left\{ \parbox{0.45\linewidth}{``number of farmers trained in improved irrigation techniques''} \right\}
    \quad , \\
    \mathcal{V}_\text{v2} & = \left\{ \parbox{0.45\linewidth}{``number of local water co-operations''} \right\}
    \quad .
  \end{align*}
  Note that all \glspl{indicator} consist in counting some elements of the system. Nevertheless, they are different from each other since they refer to different elements.
\end{example}

In particular for this study, an heat wave is described mathematically by \glspl{indicator} in table~\ref{tab:indicators_heat_wave}. Heat waves are described both in frequency and duration, through $\mathrm{HWI}$ and $\mathrm{HWML}$, respectively.
Indicators in table~\ref{tab:indicators_heavy_precipitation} are chosen to describe an heavy precipitation event. Other than duration and frequency, estimated by $\mathrm{CWD}$ and $\mathrm{Rp5mm}$, respectively, also the intensity of the event is quantified by $\mathrm{Rxp4day}$.
All indicators are generalised versions of indicators and indices frequently used in literature, e.g. \cite[2208]{2021GutierrezAnnexVI}. They are provided by \cite{2023BourgaultXclimXarray-based} and are evaluated at yearly resolution.
\begin{table}
  \centering
  \caption{Indicators describing heat wave events. They have yearly resolution.}
  \label{tab:indicators_heat_wave}
  \begin{tabular}{p{0.15\textwidth}ccp{0.15\textwidth}p{0.33\textwidth}}
    Indicator            & Symbol          & Unit        & Arguments                                                               & Definition                                                                                                                                        \\
    \hline
    Heat wave index      & $\mathrm{HWI}$  & \unit{\day} & \gls{tasmax}, $\mathrm{p1}$, $\mathrm{p2}$                              & Total number of days in sequences of at least $\mathrm{p1}$ consecutive days with $\gls{tasmax} > \mathrm{p2}$                                    \\
    Heat wave max length & $\mathrm{HWML}$ & \unit{\day} & \gls{tasmin}, \gls{tasmax}, $\mathrm{p1}$, $\mathrm{p2}$, $\mathrm{p3}$ & Maximum number of days in sequences of at least $\mathrm{p1}$ consecutive days with $\gls{tasmax} > \mathrm{p2}$ and $\gls{tasmin} > \mathrm{p3}$ \\
  \end{tabular}
\end{table}
\begin{table}
  \centering
  \caption{Indicators describing heavy precipitation events. They have yearly resolution.}
  \label{tab:indicators_heavy_precipitation}
  \begin{tabular}{p{0.15\textwidth}cccp{0.33\textwidth}}
    Indicator                                           & Symbol             & Unit                & Arguments               & Definition                                                                               \\
    \hline
    Maximum consecutive $\mathrm{p4}$-day precipitation & $\mathrm{Rxp4day}$ & \unit{\milli\metre} & \gls{pr}, $\mathrm{p4}$ & Maximum cumulative precipitation in sequences of at least $\mathrm{p4}$ consecutive days \\
    Wet days                                            & $\mathrm{Rp5mm}$   & \unit{\day}         & \gls{pr}, $\mathrm{p5}$ & Total number of days with $\gls{pr} \geq \mathrm{p5}$                                    \\
    Maximum length of wet spell                         & $\mathrm{CWD}$     & \unit{\day}         & \gls{pr}, $\mathrm{p5}$ & Maximum number of consecutive days with $\gls{pr} \geq \mathrm{p5}$                      \\
  \end{tabular}
\end{table}

In module~\ref{itm:module_4} the evaluation of \glspl{indicator} on climate and system data occurs. Concerning the system, the data collection step is explained in section~\ref{sec:Impact chain} and scalar values are readily obtained for the elements in sets $\mathcal{E}_i$ and $\mathcal{V}_k$ for any \gls{driver} $i$ or $k$. See paragraphs about data in section~\ref{sec:Impact chain} for the definition of the \glspl{indicator} of \gls{exposure} and \gls{vulnerability} used to describe each system and section~\ref{sec:Results} for their values.

A more convoluted path is needed to evaluate \glspl{indicator} of \gls{hazard}. They are functions defined by equation~\eqref{eq:math_indicator}, hence they depend on climate data and additional parameters. In tables~\ref{tab:indicators_heat_wave} and~\ref{tab:indicators_heavy_precipitation} parameters are listed to complete the definition of indicators, but they are detailed in the following paragraphs.

For each \gls{indicator}, a set of values of its parameters is defined. Ideally these sets would be continuous, to explore the whole space of possible configurations of parameters. However, for limitations intrinsic to the analysis tools, only a finite and small number of values can be considered. In the following these discrete sets are called intervals to preserve generality.
How values in these intervals are selected depends on the nature of the parameters. The selection is ultimately arbitrary, to allow greater control, e.g. remove values which are not interesting for the analysis, and to apply a form of non-parametric sampling of the input space. This is a form of space-filling design for \gls{SA} \cite[593-594]{2015DeanHandbookOf}.

To simplify the explanation, consider \gls{driver} $j$ and an \gls{indicator} $I \in \mathcal{H}_j$. This \gls{indicator} depends on some parameters, which are collected in set $P_I$, and on some \glspl{ECV}. The chosen interval for a parameter $p \in P_I$ is a set of scalar values, possibly with units, denoted by $S_p$.

If parameter $p$ is related to a \gls{ECV} (e.g. threshold on \gls{tas}), its values are sampled from the distribution of the \gls{ECV}. First all data available for the \gls{ECV} of interest are collected in a single sample, with the following conditions:
\begin{itemize}
  \item temporal coordinates belong to the averaging period $\prd{S_\text{time}}{ref}$ chosen for the \glspl{normal};
  \item spatial coordinates are ignored.
\end{itemize}
This procedure has the side effects of removing the dependence of parameter values from spatial and temporal coordinates and to increase the sample size. The sampling is not affected by existing spatial correlation between data, because it is non parametric and regards only the possible values of the \gls{ECV} and not their spatial distribution. In fact, the probability of having any value $v$ for the \gls{ECV} $T$ in the sample is
\begin{equation}
  \label{eq:variable_probability}
  \mathcal{P}(v) = \frac{1}{\abs{S_\text{lat}} \abs{S_\text{lon}} \abs{\prd{S_\text{time}}{ref}}} \sum_{y \in S_\text{lat}} \sum_{x \in S_\text{lon}} \sum_{t \in \prd{S_\text{time}}{ref}} \condition{T(y, x, t) = v}
  \quad .
\end{equation}
It is a frequentist probability and gets more accurate the larger the sample size is, by definition. %This probability is different from the conditional probability
%\begin{equation}
%  \label{eq:variable_probability_space}
%  \mathcal{P}(v \vert y,x) = \frac{1}{\abs{\prd{S_\text{time}}{ref}}} \sum_{t \in \prd{S_\text{time}}{ref}} \condition{T(y, x, t) = v}
%\end{equation}
%where the dependence on the spatial coordinates is retained.
Second, the empirical \gls{QF} of data is built from the sample, to acknowledge the shape of their true probability distribution. Minimum and maximum values are treated as the first and last quantiles, respectively. Since the number of data is large but limited, this curve is an approximation of the inverse function of the \gls{CDF} and missing data are interpolated linearly.
Third, values are chosen with the aim to sample the true probability distribution uniformly, starting from the quantile corresponding to frequency 90\%. This allows to focus the analysis on the side of the distribution which have higher values, related to extreme \glspl{risk}. The density of points may be increased where needed to have a better description of the shape of the distribution.%
\footnote{Why do not use derivative-based methods to set the density of points? The reason is again greater control on the selected values: there is no need to evaluate the derivative of the \gls{QF} in every point, just within the subintervals which are interesting for the analysis. Note that the \gls{QF} is obtained by linear interpolation between existent data values, hence the slope is already evaluated internally and the derivative is a piecewise constant function.}

If parameter $p$ is not related to a \gls{ECV}, e.g. window size for moving averages, some heuristic is applied and explained case by case where values are presented in section~\ref{sec:Results}.

The parameters indicators chosen for this study depend on are collected in table~\ref{tab:indicators_parameters}. Note that despite the definition of heat wave lasting two or more days, a window of one day is considered, i.e. $\mathrm{p1} = 1$, simply to count the number of days with extreme temperatures in a year. In particular, indicator $\mathrm{HWI}$ becomes $\mathrm{TXnn}$, see \cite[2209]{2021GutierrezAnnexVI}.
\begin{table}[h]
  \centering
  \caption{Parameters present in the definitions of hazard indicators.}
  \label{tab:indicators_parameters}
  \begin{tabular}{p{0.20\textwidth}ccp{0.33\textwidth}}
    Parameter                                  & Symbol        & Unit                        & Interval                                                                               \\
    \hline
    Consecutive days of extreme heat           & $\mathrm{p1}$ & \unit{\day}                 & Integer numbers from 1 to 31 in steps of 3                                             \\  %Interval in symbols: $\{ v \in \mathbb{N} : v = 3n + 1 \wedge n \in \mathbb{N} \wedge 0 \leq n \leq 10 \}$.
    Threshold of \gls{tasmax}                  & $\mathrm{p2}$ & \unit{\degreeCelsius}       & Quantiles 0.90, 0.97, 0.99, 0.999, 1.0 of \gls{tasmax} in the historical experiment    \\
    Threshold of \gls{tasmin}                  & $\mathrm{p3}$ & \unit{\degreeCelsius}       & Quantiles 0.90, 0.97, 0.99, 0.999, 1.0 of \gls{tasmin} in the historical experiment    \\
    Consecutive days of extreme precipitation  & $\mathrm{p4}$ & \unit{\day}                 & Integer numbers from 1 to 31                                                           \\  %Interval in symbols: $\{ v \in \mathbb{N} : 1 \leq v \leq 31 \}$.
    Threshold of \gls{pr}                      & $\mathrm{p5}$ & \unit{\milli\metre\per\day} & Quantiles 0.90, 0.97, 0.99, 0.999, 0.9999 of \gls{pr} in the historical experiment     \\
  \end{tabular}
\end{table}

After $S_p$ is defined for every $p \in P_I$, the \gls{indicator} $I$ is finally evaluated. This results in elements of set $\mathcal{H}_j$ being multidimensional arrays given by equation~\eqref{eq:math_indicator}, for every \gls{driver} $j$ of the \gls{hazard}. Different \glspl{indicator} may have different parameters, but they depend on \glspl{ECV} which same spatial and temporal coordinates $S_\text{lat} \times S_\text{lon} \times S_\text{time}$, hence they have same temporal frequency, i.e. same $S_\text{y}$.

From a computational perspective, the time complexity for the evaluation of an \gls{hazard} \gls{indicator} $I$ is a particular function $f$ of the number $\abs{S_\text{time}}$ of temporal coordinates of climate data.%
\footnote{Here time complexity is intended as number of steps of an algorithm, which can be related to physical time when executed on a calculator.}
The evaluation is then repeated for every spatial coordinate in $S_\text{lat} \times S_\text{lon}$, year in $S_\text{y}$ and combination of parameters $\underline{z} \in \prod_{p \in P_I} S_p$. In symbols the time complexity is
\begin{equation}
  \label{eq:complexity_parameters}
  O \bigg( f \big( \abs{S_\text{time}} \big) \abs{S_\text{lat}} \abs{S_\text{lon}} \abs{S_\text{y}} \prod_{p \in P_I} \abs{S_p} \bigg)
  \quad .
\end{equation}
For indicators in table~\ref{tab:indicators_parameters}, the evaluation time of an indicator for a single choice of its arguments can be always bounded by polynomial functions, $f \big( \abs{S_\text{time}} \big) = \big( \abs{S_\text{time}} \big)^a $, with $a \in \mathbb{R}$ specific to the indicator being evaluated. This means that the computation benefit from a parallel setup.

\Glspl{indicator} are also evaluated for each model available (see table~\ref{tab:CMIP6_models}). A different model may have different values for an \gls{ECV} at the same coordinates. Moreover, these differences reflect on the procedures of evaluation of parameters values. Therefore, parameters defined as quantiles of \glspl{ECV} are expressed by their sample frequency rather than their value.

These results need further elaboration. In fact, for every \gls{driver} $i$ and $k$, $\mathcal{E}_i$ and $\mathcal{V}_k$ contain scalar values which encapsulate information about the system for the chosen time period and system without reference to spatial coordinates. To obtain an analogous result for \glspl{driver} of \gls{hazard}, \glspl{indicator} are aggregated over spatial and temporal dimensions. For simplicity intermediate results are identified with the same variable $I$.

First, the temporal aggregation is performed. It consists in averaging the multidimensional array over the temporal dimension with a sample average. The outcome is multidimensional arrays depending on spatial coordinates and parameters:
\begin{equation}
  \label{eq:temporal_aggregation}
  I(y, x, t, \underline{z}) \mapsto I(y, x, \underline{z}) = \frac{1}{\abs{S_\text{y}}} \sum_{t \in S_\text{y}} I(y, x, t, \underline{z})
  \quad .
\end{equation}
Figure~\ref{fig:historical_reference_field_EC-Earth3_heat_wave_max_length} shows one of the results of the aggregation for \gls{indicator} $\mathrm{HWML}$. Climate data for coordinates related to the case study are used and the aggregation is performed over the reference period. To display the spatial distribution, indicator parameters are fixed to specific values. This representation of data is useful to focus on spatial characteristics of climate data which could affect indicators. The sample standard deviation over time, i.e. evaluated with respect to the sample mean and normalised with $\abs{S_ text{y}} - 1$, is displayed to give more information on the temporal distribution of data at each grid cell. It is not used further because it may not consider uncertainties specific to the models, which are taken into account with an ensemble average at the final steps of the analysis instead.
\begin{figure}[h]
  \centering
  \includegraphics*[keepaspectratio=true,width=\textwidth]{torino/indicators/historical/reference/field/EC-Earth3_heat_wave_max_length/1}
  \caption{$\mathrm{HWML}$ indicator temporally aggregated on the reference period for the EC-Earth3 model. Sample average and sample standard deviations are shown as spatial distributions with fixed parameters $\mathrm{p1} = \qty{4}{\day}$, $\mathrm{p2} = \qty{24.67}{\degreeCelsius}$ and $\mathrm{p3} = \qty{15.32}{\degreeCelsius}$, both thresholds of temperature are the 90th percentile. The black dot is the reference point of the case study. Effects of orography are visible, reducing daily \gls{tas} at grid cells covering mountain ranges.}
  \label{fig:historical_reference_field_EC-Earth3_heat_wave_max_length}
\end{figure}

Due to the spatial resolution of data, they may contain bias with respect to the reference period, e.g. orography may influence differently the variation of some \glspl{ECV} as can be seen in figure~\ref{fig:historical_reference_field_EC-Earth3_heat_wave_max_length}.
Therefore, for every \glspl{indicator} $I$, its variation with respect to the reference period is used,
\begin{equation}
  \label{eq:spatial_bias}
  I(y, x, \underline{z}) \mapsto I(y, x, \underline{z}) = I(y, x, \underline{z}) - \prd{I}{ref}(y, x, \underline{z})
  \quad ,
\end{equation}
where symbol $\prd{I}{ref}$ is used to refer to $I$ evaluated for the reference period, i.e. equation~\eqref{eq:temporal_aggregation} with average over set $\prd{S_\text{y}}{ref}$.%
\footnote{Another analogous quantity is the relative difference with respect to the reference period, i.e. the anomaly divided by $\prd{I}{ref}(y, x, \underline{z})$. This is not chosen because some indicator values are exactly 0, e.g. for integer-valued indicators, resulting in mathematically undefined quantities which have no meaning.}
This is analogous to evaluate \glspl{anomaly} for \glspl{indicator} instead of \glspl{ECV}.
An example of indicator anomaly is shown in figure~\ref{fig:spatial_bias_EC-Earth3_heat_wave_max_length} for scenario SSP2-4.5 and the chosen time horizons. Values of $\mathrm{HWML}$ are displayed as spatial distribution by constraining parameters of the indicator with the same values used for figure~\ref{fig:temporal_aggregation_EC-Earth3_heat_wave_max_length}, to allow comparison. For all time horizons there is an increase in the number of heat wave events and the spatial differences observed in the reference period are accentuated with time. The spatial distribution of \gls{indicator} anomalies is useful to assess the spatial dependency of indicators, e.g. in figure~\ref{fig:spatial_bias_EC-Earth3_heat_wave_max_length} differences between the reference point of the studied system and the are clearly visible. These information can be useful in \glspl{CCRA} which have a local spatial extension. The main disadvantage is on the study of effects of varying parameters: only a single combination of values can be considered at a time and this limits the visual analysis on the impacts of these values on the indicator.
\begin{figure}[h]
  \centering
  \includegraphics*[keepaspectratio=true,width=\textwidth]{torino/indicators/ssp245/spatial_bias/EC-Earth3_heat_wave_max_length/1}
  \caption{Anomalies of $\mathrm{HWML}$ for each time horizon with respect to the reference period. The spatial distributions are result of the temporal aggregation of indicators. Data refer to the case study and are from the SSP2-4.5 scenario experiment of the EC-Earth3 model. Parameters have values $\mathrm{p1} = \qty{4}{\day}$, $\mathrm{p2} = \qty{24.67}{\degreeCelsius}$ and $\mathrm{p3} = \qty{15.32}{\degreeCelsius}$, both thresholds of temperature correspond to the 90th percentile. In general the number of heat wave events increases and spatial differences caused by orography are accentuated with time.}
  \label{fig:spatial_bias_EC-Earth3_heat_wave_max_length}
\end{figure}

To compress information on spatial dependency, the spatial aggregation is performed by using \gls{EOF} analysis as a dimensionality reduction technique.%
\footnote{Terminology is varied. Here the eigenvectors, i.e. spatial patterns, are referred to as \glspl{EOF} and their coefficients, i.e. temporal patterns, are the \glspl{PC}. The object containig data is called design matrix with samples, i.e. observations, organised in rows and their features, i.e. variables which describe them, in columns. For further clarification on the terminology see \cite[626-627]{2019WilksStatisticalMethods} and for a recap on \gls{EOF} analysis see \cite[6502-6503]{2009MonahanEmpiricalOrthogonal} and \cite[1121-1122]{2007HannachiEmpiricalOrthogonal}.}
The following procedure is applied to every \gls{indicator} anomaly $I$ from equation~\eqref{eq:spatial_bias}.
First remap the multidimensional array to a bidimensional matrix, i.e. the design matrix, which is needed to perform the \gls{EOF} analysis. The procedure can be summarised in: assign $S_\text{lat} \times S_\text{lon}$ as the feature dimension of the design matrix and assign $\prod_{p \in P_I} S_p$ as the sample dimension of the design matrix. This second step establish a bijective relation between the sample dimension of the design matrix and $\prod_{p \in P_I} S_p$, hence each \gls{PC} effectively maps $I$ to a multidimensional array with coordinates in $\prod_{p \in P_I} S_p$.
Then the \gls{EOF} analysis is applied to the design matrix of the reference period. Data are centred on the sample mean and a spatial weighting considering the curvature of Earth is applied, to avoid losing geographic information \cite{2009BaldwinSpatialWeighting}: each grid cell is multiplied by $\sqrt{\cos{(y)}}$ where $y \in S_\text{lat}$ is its latitude.
Figure~\ref{fig:explained_EC-Earth3} shows the cumulative explained variance resulting from the \gls{EOF} analysis of all indicators for model EC-Earth3. A full decomposition is performed but to have plots easier to read it is truncated to the first five \glspl{PC}. However, the first one collects most of the variance in the sample dimension and this is valid for all models,%
\footnote{Analogous plots for the other models are available at \url{https://github.com/mirasac/mscunito-thesis-document/tree/main/figures/torino/indicators/historical/reference/hazard/explained}.}
ensuring that most of the underlying information related to the spatial dimensions are compressed in the first \gls{PC}.
\begin{figure}[h]
  \centering
  \includegraphics*[keepaspectratio=true,width=\textwidth]{torino/indicators/historical/reference/hazard/explained/EC-Earth3}
  \caption{Cumulative explained variance resulting from the decomposition in \glspl{EOF} of all indicators for model EC-Earth3. The dashed line represents the threshold of 95\% and only the first five components are displayed for clarity.}
  \label{fig:explained_EC-Earth3}
\end{figure}

Vector components of the first two \glspl{EOF} are shown as spatial fields in figure~\ref{fig:EOF_EC-Earth3_heat_wave_max_length} for indicator $\mathrm{HWML}$ and model EC-Earth3. This plot shows which features have larger weight in the decomposition, since the first two \glspl{PC} together account for the 99\% of the explained variance. Values are normalised with the $L^2$ norm to compare between various models and indicators. Same normalisation is applied in figure~\ref{fig:PC_EC-Earth3} where data for each indicator for model EC-Earth3 in the reference period are projected on the first two \glspl{EOF}.%
\footnote{Both plots for other models and indicators are available at \url{https://github.com/mirasac/mscunito-thesis-document/tree/main/figures/torino/indicators/historical/reference/hazard/EOF} and \url{https://github.com/mirasac/mscunito-thesis-document/tree/main/figures/torino/indicators/historical/reference/hazard/PC}, respectively.}
Indicators $\mathrm{HWI}$, $\mathrm{HWML}$ and $\mathrm{Rxp4day}$ present distribution which are not ascribable to linear correlations, hence other tools may be suitable to study their correlations, e.g. mutual information.
\begin{figure}[h]
  \centering
  \includegraphics*[keepaspectratio=true,width=\textwidth]{torino/indicators/historical/reference/hazard/EOF/EC-Earth3_heat_wave_max_length}
  \caption{}
  \label{fig:EOF_EC-Earth3_heat_wave_max_length}
\end{figure}
\begin{figure}[h]
  \centering
  \includegraphics*[keepaspectratio=true,width=\textwidth]{torino/indicators/historical/reference/hazard/PC/EC-Earth3}
  \caption{First two \glspl{PC} of indicators for model EC-Earth3 in the reference period. Values are normalised with $L^2$ norm. Non-linear correlations are visible for $\mathrm{HWI}$, $\mathrm{HWML}$ and $\mathrm{Rxp4day}$ indicators.}
  \label{fig:PC_EC-Earth3}
\end{figure}

Once the orthogonal basis for the reference period is evaluated, every indicator for the future time horizons is projected on the first vector of the basis. The result is used as new indicator, depending only on its parameters $\underline{z} \in \prod_{p \in P_I} S_p$:
\begin{equation}
  \label{eq:spatial_aggregation}
  I(y, x, \underline{z}) \mapsto I(\underline{z})% = \EOF{I(y, x, \underline{z})}  % If the commented notation is used, then add to main.tex: \DeclarePairedDelimiterXPP{\EOF}[1]{\mathrm{EOF}}{[}{]}{}{#1}.
  \quad .
\end{equation}
The procedure is repeated for each indicator $I \in \mathcal{H}_j$ of each \gls{driver} $j$ with data from models in each scenario and time horizon.

The projection corresponds to a rotation in the space of all spatial coordinates and this is geometrically possible because feature and sample dimensions are equal for all periods, since parameters obtained from the reference period are used for the indicator in same scenario and model. A side effect of the rotation is to possibly obtain negative values which the original indicator was not allowed to get. This is an outcome of the mathematical treatment of quantities and the physical meaning of scalar quantities after the rotation is seldom preserved.

The first \gls{EOF} is the direction in the feature dimension which maximises the variance among all values of parameters, i.e. the sample dimension. With the procedure for spatial aggregation presented above, the expectation is that higher variance in the space of all parameters corresponds to greater effects on the final \gls{risk} value. This reasoning extends to the choice of the orthogonal basis: relevant spatial information are gathered in the first \gls{EOF} of the reference period and the projection on this direction allows to compare the same information in future periods, potentially assessing their change.

On the contrary, applying an \gls{EOF} analysis to every period and using the first \gls{PC} invalids the comparison of relevant spatial information across different periods. In other words, the direction of maximum variance is not guaranteed to be the same across periods.

Although it is common to use \gls{EOF} analysis to decouple the temporal dimension from the spatial ones \cite{2007HannachiEmpiricalOrthogonal}, this procedure is not applied in the present study because each analysed function depends on additional arguments. If spatial aggregation were performed first, either it is applied independently to each combination of parameter values or every dimension which is not s spatial one is included the sample dimension. In both cases, the resulting \gls{indicator} would be function $I(t, \underline{z})$, however the resulting orthogonal basis would not allow the comparison between different time horizons. In fact, in the first case there is no guarantee that the direction of maximum variance of the indicator on the sample dimension $S_\text{y}$ is the same for every combination of parameter values. In the second case the sample dimension is $S_\text{y} \times \prod_{p \in P_I} S_p$, hence any known interpretation of the results of \gls{EOF} analysis in terms of time and space is not applicable.

To execute module~\ref{itm:module_5}, first the scale of each \gls{indicator} is defined. In this work all \glspl{indicator} are numeric values and may have both metric or categorical scales (i.e. values are distributed uniformly or not, respectively, cf. \cite[109]{2017GIZTheVulnerability}).
When metric scales are involved, the methodology suggests to apply the min-max normalisation. Instead, in the present work \glspl{indicator} which are scalar values are not transformed,%
\footnote{Formally they are divided by a unit value of their quantity to obtain dimensionless values, which are trivially compatible and easily used as arguments in mathematical functions.}
while \glspl{indicator} which depend on parameters are standardised, i.e. substituted by their z-score. More in detail, for any \gls{indicator} $I$ undergoing normalisation, the new value is
\begin{equation}
  \label{eq:z-score}
  I(\underline{z}) \mapsto I(\underline{z}) = \frac{I(\underline{z}) - \mu_I}{\sigma_I}
\end{equation}
where the sample mean
\begin{equation}
  \label{eq:sample_mean}
  \mu_I = \frac{1}{\prod_{p \in P_I} \abs{S_p}} \sum_{\underline{z} \in \prod_{p \in P_I} S_p} \prd{I}{ref}(\underline{z})
\end{equation}
and the sample standard deviation
\begin{equation}
  \label{eq:sample_standard_deviation}
  \sigma_I = \sqrt{\frac{1}{\prod_{p \in P_I} \abs{S_p} - 1} \sum_{\underline{z} \in \prod_{p \in P_I} S_p} \big( \prd{I}{ref}(\underline{z}) - \mu_I \big)^2}
\end{equation}
are calculated using values obtained for the reference period $\prd{S_\text{y}}{ref}$ \cite[84]{2008OECDHandbookOn}. The advantage of equation~\eqref{eq:z-score} with respect to min-max normalisation is to be flexible when new values are introduced, in fact they are measured in terms of statistics of the reference period without breaking the normalisation.%
\footnote{See section~\ref{sec:Min-max normalisation} for further insight on why min-max normalisation is not used.}
To normalise categorical scales, the methodology suggests first to group the values in five classes, then replace them with specific values in the range $[0, 1]$, see \cite[115-116]{2017GIZTheVulnerability}. Higher normalised values are associated to more negative impacts. However, this case does not occur in the present study since every \gls{indicator} with categorical scale is a constant value. Not normalising some \glspl{indicator} may seem wrong since normalisation is a requisite to compare them, but the reason is supported mathematically in the next paragraphs.

For module~\ref{itm:module_6}, the weight $w_I$ of each \gls{indicator} $I$ is set to 1, because no particular influence on the final \gls{risk} is known a priori. Since \glspl{indicator} are unique, there is not ambiguity to identify their weights with their names as labels. This choice of weighting has not effects on the final \gls{risk} value, as explained in section~\ref{sec:Evaluation of risk}.
Then, for each \gls{determinant} the weighted mean of its \glspl{indicator} is computed. Since all \glspl{indicator} are weighted equally, the result equals the arithmetic mean. In \cite[51]{2017GIZRiskSupplement} this process is represented graphically with a single \gls{indicator} for each \gls{driver}.
The results are a scalar value for \gls{exposure}
\begin{equation}
  \label{eq:exposure_aggregated}
  E = \frac{1}{\sum_i \sum_{I \in \mathcal{E}_i} w_I} \sum_i \sum_{I \in \mathcal{E}_i} w_I I
  \quad ,
\end{equation}
a scalar value for \gls{vulnerability}
\begin{equation}
  \label{eq:vulnerability_aggregated}
  V = \frac{1}{\sum_k \sum_{I \in \mathcal{V}_k} w_I} \sum_k \sum_{I \in \mathcal{V}_k} w_I I
\end{equation}
and a scalar function for \gls{hazard} $H : \prod_j \prod_{I \in \mathcal{H}_j} \prod_{p \in P_I} S_p \to \mathbb{R}$, which depends on all parameters, defined as
\begin{equation}
  \label{eq:hazard_aggregated}
  H(\underline{z}) = \frac{1}{\sum_j \sum_{I \in \mathcal{H}_j} w_I} \sum_j \sum_{I \in \mathcal{H}_j} w_I I(\underline{z}_I)
\end{equation}
where $\underline{z}_I \in \prod_{p \in P_I} S_p$ is the sequence of values for parameters which are arguments of $I$.
Note that the there is no need to treat \glspl{driver} of \gls{adaptive_capacity} and \gls{sensitivity} separately because the aggregation procedure is applied equally to them.

Note that in module~\ref{itm:module_6} a relation between \glspl{indicator} within the same \gls{determinant} is established through the aggregation procedure, hence the results may be regarded as category~\ref{itm:category_1} complex \glspl{hazard}.
Moreover, the concept of intermediate impact, which mediates \glspl{driver} of hazard and \gls{vulnerability}, are a form of category~\ref{itm:category_2} complex \gls{hazard} \cite[33]{2017GIZRiskSupplement}.



\subsection{Evaluation of risk}
\label{sec:Evaluation of risk}
Scalar values representing each \gls{determinant} of \gls{risk} are aggregated into a single value. The aggregation procedure is a weighted mean, see module~\ref{itm:module_7}, and the weights assigned to each \gls{determinant} are $w_E = 1$, $w_H = 1$ and $w_V = 1$. Then, analogously to the aggregation of \gls{hazard} \glspl{indicator} in equation~\ref{eq:hazard_aggregated}, the value for \gls{risk} is a scalar function $R : \prod_j \prod_{I \in \mathcal{H}_j} \prod_{p \in P_I} S_p \to \mathbb{R}$ which depends on all parameters:
\begin{equation}
  \label{eq:risk_aggregated}
  R(\underline{z}) = \frac{w_E E + w_H H(\underline{z}) + w_V V}{w_E + w_H + w_V}
  \quad .
\end{equation}
The \gls{risk} value is a linear function of normalised \gls{hazard} \glspl{indicator}. This can be seen easily by manipulating equation~\eqref{eq:risk_aggregated},
\begin{equation}
  \label{eq:risk_linearity}
  R(\underline{z}) = c_0 + \frac{w_H H(\underline{z})}{w_E + w_H + w_V} = c_0 + c_1 \sum_j \sum_{I \in \mathcal{H}_j} w_I I(\underline{z}_I)
\end{equation}
with $c_0 = \frac{w_E E + w_V V}{w_E + w_H + w_V}$ and $c_1 = \frac{w_H}{(w_E + w_H + w_V) \sum_j \sum_{I \in \mathcal{H}_j} w_I}$, and it holds true as long as the aggregation procedures for \gls{risk} and \gls{hazard} are linear.

One of the problems which justifies this work can be stated using equation~\eqref{eq:risk_aggregated}: given different choices of \glspl{indicator} or parameters, the resulting \gls{risk} value can be the same, as long as the differences in values balance out.
\begin{example}
  \Gls{risk} is assessed for a system, $E$ and $V$ are known and only one \gls{driver} of \gls{hazard} is considered. Two sets of different \glspl{indicator} are prepared, $\mathcal{H}'$ and $\mathcal{H}''$, functions may differ only in the values of their parameters.These alternatives would be equivalent to describe the \gls{driver} mathematically from different points of view.
  
  Even if all \glspl{indicator} have different values after the calculation steps, the aggregated values of \gls{hazard} $H'$ and $H''$ for sets $\mathcal{H}'$ and $\mathcal{H}''$, respectively, are ideally equal. The same same \gls{risk} value $R$ results from the aggregation, since $E$ and $V$ do not depend on the choices regarding the \gls{hazard}.
  This is the expected outcome, because changing the mathematical description of the physical phenomenon should not change the final \gls{risk}.
\end{example}

A final non-linear transformation is performed on \gls{risk} value $R$, to simplify the presentation and comparison of \gls{risk} values.
Values obtained from all the combinations of parameters are classified accordingly to five categories, in increasing order of severity:\cite[53]{2017GIZRiskSupplement}
\begin{enumerate}
  \item $\riski$;
  \item $\riskii$;
  \item $\riskiii$;
  \item $\riskiv$;
  \item $\riskv$.
\end{enumerate}
This transformation can be formalised as a piecewise function $r : \prod_j \prod_{I \in \mathcal{H}_j} \prod_{p \in P_I} S_p \to \{ \riski, \riskii, \riskiii, \riskiv, \riskv \}$, where the thresholds for each piece are the quantiles of the image of $\prod_j \prod_{I \in \mathcal{H}_j} \prod_{p \in P_I} S_p$ through function $R$ for the reference period:
\begin{equation}
  \label{eq:risk_categorical}
  r(\underline{z}) =
  \begin{cases}
    \riski & R(\underline{z}) < q_1 \\
    \riskii & q_1 \le R(\underline{z}) < q_2 \\
    \riskiii & q_2 \le R(\underline{z}) < q_3 \\
    \riskiv & q_3 \le R(\underline{z}) < q_4 \\
    \riskv & R(\underline{z}) \ge q_4
  \end{cases}
  \quad .
\end{equation}
Thresholds $q_1$, $q_2$, $q_3$ and $q_4$ are calculated from \gls{risk} values of the reference period because \gls{hazard} \glspl{driver} are supposed to change \gls{risk} and \glspl{impact} with time. Moreover, the pieces of the function reflect the fact that the image of $R$ is not bounded, due to the aggregated values of \glspl{determinant} being not bounded by the chosen normalisation. This allows to account for extreme values of \gls{risk} in periods different from the reference.

Module~\ref{itm:module_7} addresses the possible aggregation of multiple sub-risks into an overall \gls{risk} value \cite[54]{2017GIZRiskSupplement}. According to section~\ref{sec:Complex risk}, the outcome would be a complex risk belonging to category~\ref{itm:category_3}.
This additional elaboration is not implemented in the present work because an individual \gls{risk} is studied, i.e. the climate risk.
